{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9c077b",
   "metadata": {},
   "source": [
    "# Chapter 3: Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad36c8",
   "metadata": {},
   "source": [
    "### Python Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cb0d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1.0, 2.0, 1.0]\n",
    "a[2] = 3.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed62820",
   "metadata": {},
   "source": [
    "## 3.1 Constructing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a73593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b09274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395caa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b8620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11dd74d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ccde37",
   "metadata": {},
   "source": [
    "## 3.2 Anatomy of tensors\n",
    "\n",
    "Example: store 3 vertices of coords (4,1), (5,3) and (2,1) using a 1D tensor with even-indexes for x and odd-indexes for y coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9e3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a308da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points2 = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127f7af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points == points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "947cd233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points - points2 == torch.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26aaf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points + points2 == 2*points2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a619a",
   "metadata": {},
   "source": [
    "First coord:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d6d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99decda5",
   "metadata": {},
   "source": [
    "Storing the coords as a 2D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57b4bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6c127",
   "metadata": {},
   "source": [
    "To know about the tensor dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f0e7ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da9b97",
   "metadata": {},
   "source": [
    "Initialize the tensor by providing dimensions as a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29728d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3, 2)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd653e0",
   "metadata": {},
   "source": [
    "Accessing the elements using two indexes (like in matlab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e984be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7345809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be02e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[-1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23d4b88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4., 1.]), tensor([5., 3.]), tensor([2., 1.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0], points[1], points[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b96a5",
   "metadata": {},
   "source": [
    "## 3.3 Indexing tensors\n",
    "Same indexing operators as python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cb59d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = list(range(6))\n",
    "some_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a4cc8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b56cc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5e3b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d575d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01d4585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0aaede7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:4:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2c319",
   "metadata": {},
   "source": [
    "Same applies to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "879ed8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a990d7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c317e69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f27c29cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a29d58fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "141808b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4., 1.],\n",
       "          [5., 3.],\n",
       "          [2., 1.]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None][None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b5150",
   "metadata": {},
   "source": [
    "## 3.4 Named tensors\n",
    "Just like structs, shapes, dicts, tensor labels to each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90774c97",
   "metadata": {},
   "source": [
    "We have an image and we want to convert to grayscale, in this example we use random values because we're lazy. The format if intensities of for each R, G and B channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b1cdf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1835, -0.7685, -0.7324,  0.8350, -0.1623],\n",
       "         [ 0.7558,  1.3816, -0.7967,  0.3388, -1.6492],\n",
       "         [-1.2924,  1.8309, -0.1060,  0.8038, -0.5510],\n",
       "         [-0.5303, -0.1349,  2.3907,  0.3473,  0.5440],\n",
       "         [ 0.4286,  0.8241,  0.9571,  0.3551, -0.8520]],\n",
       "\n",
       "        [[ 1.5612,  0.6536,  0.2390, -3.1533, -1.3207],\n",
       "         [-0.9403,  0.5684,  0.2527, -0.4097,  1.5437],\n",
       "         [ 0.1288, -0.9305,  0.3525,  0.0846,  0.5935],\n",
       "         [-1.7448,  0.5884, -0.1644, -0.3367, -0.0112],\n",
       "         [-1.8768, -1.2188, -1.1649, -0.6507,  0.2935]],\n",
       "\n",
       "        [[ 0.5932, -0.4138,  0.1424,  0.2035, -0.8590],\n",
       "         [ 0.0141,  0.0541,  0.1619,  0.2591,  0.6742],\n",
       "         [ 0.2784, -0.7470, -0.0204, -1.1171,  1.5238],\n",
       "         [ 1.2570,  0.3234, -1.0645,  0.5677,  1.3964],\n",
       "         [-1.5203,  0.2667,  0.8111,  1.0509, -1.5224]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcbea5d",
   "metadata": {},
   "source": [
    "To convert to grayscale we use [Luma](https://en.wikipedia.org/wiki/Luma_(video)) to calculate the greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecb0dbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d456b707",
   "metadata": {},
   "source": [
    "Also, lets suppose we have 2 batches of images, so we have another tensor dimension, the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aeb81613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.7502e-02, -1.8397e-02, -1.4817e+00,  8.9389e-01,  7.4074e-01],\n",
       "          [ 2.0379e+00,  1.5996e+00, -4.1546e-01,  9.4662e-01, -9.1306e-01],\n",
       "          [ 4.6170e-01,  1.2285e+00,  4.5296e-01,  4.8263e-01,  7.2630e-01],\n",
       "          [ 1.3624e+00, -1.2550e+00,  1.0906e+00, -1.9803e-01, -1.7467e-01],\n",
       "          [-6.7358e-01,  3.0278e-01,  1.4443e+00,  7.1786e-01, -2.7943e-01]],\n",
       "\n",
       "         [[-4.2959e-01, -8.0975e-01, -4.9859e-01,  1.0210e+00, -9.9131e-01],\n",
       "          [-1.3293e+00,  5.1605e-01,  1.7589e+00, -1.8488e+00,  1.4379e+00],\n",
       "          [ 6.2951e-01, -1.3813e+00,  6.5393e-01,  6.4647e-01,  1.3148e-01],\n",
       "          [-7.9886e-02, -1.5476e-02, -1.7365e+00,  9.4626e-01,  7.5388e-01],\n",
       "          [-5.4763e-01,  4.9903e-01, -5.5369e-01,  1.2497e-01, -2.9233e-01]],\n",
       "\n",
       "         [[-2.8719e-01, -4.9088e-01,  2.3721e-01, -2.1771e+00,  1.1075e+00],\n",
       "          [ 2.5897e+00,  1.2346e+00, -6.0857e-02,  3.0953e-02, -1.6737e+00],\n",
       "          [ 1.4982e+00, -1.6663e-01, -7.2700e-01, -4.6998e-01, -4.5466e-01],\n",
       "          [-7.4687e-01,  5.4350e-01, -1.0227e+00, -9.3474e-01,  9.0877e-01],\n",
       "          [ 1.2302e-01, -6.5710e-01, -8.7506e-01, -2.3246e+00, -8.5956e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.9792e+00, -1.4913e-01, -5.4205e-01,  2.1447e-02, -4.1853e-01],\n",
       "          [-2.2471e+00,  5.9696e-01,  7.9388e-01,  1.8787e+00, -1.0898e-01],\n",
       "          [ 1.0591e+00,  4.7454e-01,  9.8921e-01,  3.9377e-01, -1.0216e+00],\n",
       "          [-2.0381e+00, -1.4455e-03, -8.5281e-01, -7.3297e-01, -1.3870e+00],\n",
       "          [-1.0997e+00, -8.9672e-01,  7.5657e-01,  7.8597e-01, -1.2448e+00]],\n",
       "\n",
       "         [[-1.6229e+00, -6.0514e-01, -1.0806e+00, -7.7889e-01,  2.1801e+00],\n",
       "          [ 1.3267e+00,  5.9777e-01,  1.7698e-01,  3.2617e-02, -1.4366e+00],\n",
       "          [-3.3281e-01, -7.2454e-01, -5.7877e-01, -1.7432e+00, -2.9598e-01],\n",
       "          [ 1.5300e+00,  2.7470e+00, -2.3550e-01,  8.9143e-01, -1.7023e+00],\n",
       "          [-1.0644e+00, -4.1714e-01, -1.6807e+00,  1.0963e+00,  5.2619e-01]],\n",
       "\n",
       "         [[-8.4142e-01, -1.0886e-01, -4.3554e-01,  8.0626e-01,  1.0173e+00],\n",
       "          [-9.3628e-01, -2.4960e-01, -8.9272e-01,  2.0796e-01, -2.7575e-01],\n",
       "          [ 2.1744e+00, -1.1262e+00,  1.7609e+00,  1.0825e+00, -3.2442e-01],\n",
       "          [-8.9931e-02,  1.0306e+00,  1.0346e-01, -8.6157e-01, -6.7456e-01],\n",
       "          [-1.5835e+00,  6.1141e-01, -7.0586e-01, -6.1354e-01, -6.4096e-01]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aca21c",
   "metadata": {},
   "source": [
    "We calculate the means from the last 3 dimensions, because RBG channels are at the end, so we generate a new tensor with the `mean(dim -3, dim -2, dim -1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90e72dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3236, -0.1762, -0.1170, -0.7049, -0.7807],\n",
       "         [-0.0568,  0.6680, -0.1273,  0.0628,  0.1895],\n",
       "         [-0.2951,  0.0511,  0.0753, -0.0762,  0.5221],\n",
       "         [-0.3394,  0.2590,  0.3873,  0.1927,  0.6431],\n",
       "         [-0.9895, -0.0427,  0.2011,  0.2518, -0.6936]]),\n",
       " tensor([[[-0.2098, -0.4397, -0.5810, -0.0874,  0.2856],\n",
       "          [ 1.0994,  1.1168,  0.4275, -0.2904, -0.3830],\n",
       "          [ 0.8631, -0.1065,  0.1266,  0.2197,  0.1344],\n",
       "          [ 0.1786, -0.2423, -0.5562, -0.0622,  0.4960],\n",
       "          [-0.3661,  0.0482,  0.0052, -0.4939, -0.4771]],\n",
       " \n",
       "         [[-1.4812, -0.2877, -0.6861,  0.0163,  0.9263],\n",
       "          [-0.6189,  0.3150,  0.0260,  0.7064, -0.6071],\n",
       "          [ 0.9669, -0.4587,  0.7238, -0.0890, -0.5473],\n",
       "          [-0.1994,  1.2587, -0.3283, -0.2344, -1.2546],\n",
       "          [-1.2492, -0.2341, -0.5433,  0.4229, -0.4532]]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive, batch_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db857c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
