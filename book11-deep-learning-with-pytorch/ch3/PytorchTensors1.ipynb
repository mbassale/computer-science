{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9c077b",
   "metadata": {},
   "source": [
    "# Chapter 3: Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad36c8",
   "metadata": {},
   "source": [
    "### Python Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cb0d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1.0, 2.0, 1.0]\n",
    "a[2] = 3.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed62820",
   "metadata": {},
   "source": [
    "## 3.1 Constructing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a73593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b09274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395caa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b8620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11dd74d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ccde37",
   "metadata": {},
   "source": [
    "## 3.2 Anatomy of tensors\n",
    "\n",
    "Example: store 3 vertices of coords (4,1), (5,3) and (2,1) using a 1D tensor with even-indexes for x and odd-indexes for y coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9e3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a308da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points2 = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127f7af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points == points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947cd233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points - points2 == torch.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e26aaf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points + points2 == 2*points2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a619a",
   "metadata": {},
   "source": [
    "First coord:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d6d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99decda5",
   "metadata": {},
   "source": [
    "Storing the coords as a 2D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b4bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6c127",
   "metadata": {},
   "source": [
    "To know about the tensor dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0e7ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da9b97",
   "metadata": {},
   "source": [
    "Initialize the tensor by providing dimensions as a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29728d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3, 2)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd653e0",
   "metadata": {},
   "source": [
    "Accessing the elements using two indexes (like in matlab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e984be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7345809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be02e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[-1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23d4b88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4., 1.]), tensor([5., 3.]), tensor([2., 1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0], points[1], points[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b96a5",
   "metadata": {},
   "source": [
    "## 3.3 Indexing tensors\n",
    "Same indexing operators as python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cb59d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = list(range(6))\n",
    "some_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a4cc8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b56cc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e3b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d575d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d4585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aaede7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:4:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2c319",
   "metadata": {},
   "source": [
    "Same applies to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "879ed8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a990d7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c317e69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27c29cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a29d58fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "141808b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4., 1.],\n",
       "          [5., 3.],\n",
       "          [2., 1.]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None][None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b5150",
   "metadata": {},
   "source": [
    "## 3.4 Named tensors\n",
    "Just like structs, shapes, dicts, tensor labels to each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90774c97",
   "metadata": {},
   "source": [
    "We have an image and we want to convert to grayscale, in this example we use random values because we're lazy. The format if intensities of for each R, G and B channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b1cdf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4930, -0.8106, -0.5240,  0.0713,  0.1247],\n",
       "         [ 0.4812,  0.8242, -2.0381,  1.2236, -0.2526],\n",
       "         [ 0.5561,  0.7216, -1.3518, -0.7476,  0.6972],\n",
       "         [-1.0888,  1.1922, -0.8258,  1.0155, -0.1985],\n",
       "         [-1.5539, -0.0048,  1.2896,  1.5456, -1.2595]],\n",
       "\n",
       "        [[-0.0349,  0.5411,  0.1076, -0.4084,  0.9183],\n",
       "         [-0.9313, -0.7589, -0.0746,  0.0816, -1.2264],\n",
       "         [-0.5843,  1.1945,  1.1861, -2.1043,  0.1550],\n",
       "         [ 0.2470, -0.9824, -1.2079, -1.1832,  0.4047],\n",
       "         [-0.2835,  0.7244, -0.3604,  0.2474,  0.7030]],\n",
       "\n",
       "        [[ 1.2969,  2.0338,  2.7685, -1.4814, -0.5952],\n",
       "         [ 0.5902, -1.2456,  2.3021, -0.2727, -2.2113],\n",
       "         [-0.4184, -1.5095,  0.9897, -0.7600,  0.5143],\n",
       "         [-0.0916,  2.7021, -0.0828,  0.0807,  0.6748],\n",
       "         [-0.5653,  0.0968, -0.8273, -0.8807, -0.6210]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcbea5d",
   "metadata": {},
   "source": [
    "To convert to grayscale we use [Luma](https://en.wikipedia.org/wiki/Luma_(video)) to calculate the greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecb0dbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d456b707",
   "metadata": {},
   "source": [
    "Also, lets suppose we have 2 batches of images, so we have another tensor dimension, the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeb81613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7610,  1.1298,  0.6138, -0.6524,  0.2266],\n",
       "          [-0.7460, -0.6809,  1.2057,  0.4349, -2.7687],\n",
       "          [-0.9533, -0.3425,  1.8433,  1.7883, -1.8487],\n",
       "          [-0.9504,  1.2802, -0.1329,  1.0089, -1.2179],\n",
       "          [ 1.6961, -0.6754, -0.9830, -1.2065, -0.6478]],\n",
       "\n",
       "         [[ 1.0637,  0.5804,  1.3389, -1.6186,  1.5204],\n",
       "          [-0.2378,  1.5774, -0.0360, -0.4198, -0.9024],\n",
       "          [-0.2940, -0.6171, -0.9418, -0.4290, -1.7693],\n",
       "          [-0.6904,  1.9634,  1.1850,  2.7678, -1.2454],\n",
       "          [-0.0126,  0.6132, -0.7804, -0.5841, -0.2693]],\n",
       "\n",
       "         [[ 0.1844, -0.6011,  0.2804,  0.0874, -0.3683],\n",
       "          [ 1.1970,  0.5687,  1.4343,  0.9489, -0.0914],\n",
       "          [ 0.3175, -0.8007, -0.6678, -0.2359, -2.1677],\n",
       "          [ 0.1072, -0.5628,  0.6466,  0.6744, -0.8025],\n",
       "          [ 0.3714, -0.7287, -1.3414, -1.0329, -0.1620]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2666, -0.4440, -0.4953, -1.1657, -0.2702],\n",
       "          [ 0.8494,  0.8494,  0.5698, -0.3463, -1.5398],\n",
       "          [ 0.3595,  1.3480,  0.8818,  0.4591, -0.8963],\n",
       "          [-0.2353,  1.6031,  0.9662, -1.4153,  0.1664],\n",
       "          [ 0.9358, -0.9213,  1.4881,  0.4438, -0.5989]],\n",
       "\n",
       "         [[-0.7382,  3.0002,  0.3235, -2.4571, -0.4856],\n",
       "          [-0.2857,  0.5974,  0.7482, -0.3645, -1.3097],\n",
       "          [ 0.3346, -0.5253, -2.1282, -0.0774,  1.3532],\n",
       "          [ 0.5760,  1.3942, -0.1755,  0.5728,  0.1972],\n",
       "          [-1.2722, -0.0200,  1.0651,  0.5411, -1.6226]],\n",
       "\n",
       "         [[-0.3253,  0.9185,  1.2040, -2.2287,  0.4164],\n",
       "          [-0.5501, -0.0520,  0.6173,  0.3645, -0.5138],\n",
       "          [-0.5079,  1.7418,  1.0646,  1.2448,  0.3896],\n",
       "          [ 0.6646,  0.9616, -0.0921, -1.0342,  1.2286],\n",
       "          [-0.5259,  2.1245,  1.8075, -0.4198,  0.9756]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aca21c",
   "metadata": {},
   "source": [
    "We calculate the means from the last 3 dimensions, because RBG channels are at the end, so we generate a new tensor with the `mean(dim -3, dim -2, dim -1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90e72dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2563,  0.5881,  0.7840, -0.6062,  0.1493],\n",
       "         [ 0.0467, -0.3934,  0.0631,  0.3441, -1.2301],\n",
       "         [-0.1489,  0.1356,  0.2747, -1.2039,  0.4555],\n",
       "         [-0.3111,  0.9706, -0.7055, -0.0290,  0.2937],\n",
       "         [-0.8009,  0.2721,  0.0340,  0.3041, -0.3925]]),\n",
       " tensor([[[ 0.1624,  0.3697,  0.7444, -0.7278,  0.4596],\n",
       "          [ 0.0711,  0.4884,  0.8680,  0.3213, -1.2541],\n",
       "          [-0.3099, -0.5868,  0.0779,  0.3745, -1.9286],\n",
       "          [-0.5112,  0.8936,  0.5662,  1.4837, -1.0886],\n",
       "          [ 0.6850, -0.2636, -1.0349, -0.9412, -0.3597]],\n",
       " \n",
       "         [[-0.2657,  1.1582,  0.3441, -1.9505, -0.1131],\n",
       "          [ 0.0045,  0.4649,  0.6451, -0.1154, -1.1211],\n",
       "          [ 0.0621,  0.8548, -0.0606,  0.5422,  0.2822],\n",
       "          [ 0.3351,  1.3196,  0.2329, -0.6256,  0.5307],\n",
       "          [-0.2874,  0.3944,  1.4536,  0.1884, -0.4153]]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive, batch_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4db857c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c54dbe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac53c9b",
   "metadata": {},
   "source": [
    "### Using named tensors for self-documenting code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b1304",
   "metadata": {},
   "source": [
    "Specifying dimension names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ee84a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bassa\\AppData\\Local\\Temp\\ipykernel_4048\\2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10/core/TensorImpl.h:1761.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8edb6",
   "metadata": {},
   "source": [
    "Creating new tensors with dimension names from unamed tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92f235f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch_named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print('img named:', img_named.shape, img_named.names)\n",
    "print('batch_named:', batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b8bad",
   "metadata": {},
   "source": [
    "Create a new tensor aligned with the same column/dim ordering by using names to match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60f9e832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d3586",
   "metadata": {},
   "source": [
    "Tensor operations can take a named dimesion as arg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d008fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50c9bc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], names=('rows', 'columns'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named - (img_named*weights_aligned).sum('channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a47cd7",
   "metadata": {},
   "source": [
    "Names checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f008520f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4048\\9594579.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgray_named\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_named\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights_named\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'channels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match."
     ]
    }
   ],
   "source": [
    "gray_named = (img_named[..., :3] * weights_named).sum('channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b526a7a",
   "metadata": {},
   "source": [
    "Drop named tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d3b6c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dce36e",
   "metadata": {},
   "source": [
    "## 3.5 Tensor element types\n",
    "\n",
    "Tensor constructor argument `dtype` specifies the numerical data type of each tensor scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f1976",
   "metadata": {},
   "source": [
    "### 3.5.3 Managing a tensor's dtype attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bf59c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e47d1f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]], dtype=torch.float64),\n",
       " torch.float64,\n",
       " torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points, double_points.dtype, torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d2682a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]], dtype=torch.int16),\n",
       " torch.int16,\n",
       " torch.int16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_points, short_points.dtype, torch.int16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f9a3c",
   "metadata": {},
   "source": [
    "Using casting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da834a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()\n",
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e724fb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(10, 2).to(dtype=torch.short)\n",
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d516efe",
   "metadata": {},
   "source": [
    "Types are converted to the larget type automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "879a0cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.to(torch.short)\n",
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376af7ed",
   "metadata": {},
   "source": [
    "## 3.6 The tensor API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527ecd9",
   "metadata": {},
   "source": [
    "Use methods from the `torch` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "975ee90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a_t = torch.transpose(a, 0, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "439ca10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8277e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9159a13c",
   "metadata": {},
   "source": [
    "Or call methods from the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90e07351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a_t = a.transpose(0, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c11276a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f0916e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35299950",
   "metadata": {},
   "source": [
    "## 3.7 Tensors: Scenic views of storage\n",
    "\n",
    "Accessing underlying storage by using the `storage()` method of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cf1cf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ff677",
   "metadata": {},
   "source": [
    "Index directly into storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4030b13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points_storage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a6c9132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a673f",
   "metadata": {},
   "source": [
    "Changing storage value, modifies the tensor also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53b71971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883413a",
   "metadata": {},
   "source": [
    "### 3.7.2 Modifying stored values: In-place operations\n",
    "\n",
    "In-place modification operations have an underscore (`_`) suffix, those without underscore always return a new tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9110c5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5b2dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83d2a069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5432cc8",
   "metadata": {},
   "source": [
    "## 3.8 Tensor metadata: Size, offset, and stride\n",
    "\n",
    "- **Size:** dimensions, shape\n",
    "- **Offset:** where is the first element in the storage\n",
    "- **Stride:** how many storage units we need to skip per dimension to get the next element. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1b08a",
   "metadata": {},
   "source": [
    "### 3.8.1 Views of another tensor's storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ba60cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b5dcceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e40d53b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61ed16",
   "metadata": {},
   "source": [
    "To get the stride, we call the `stride()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "212d20af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421c2af",
   "metadata": {},
   "source": [
    "We can use the query the `second_point` tensor and see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "beab9d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "641869c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e4f7e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d683b",
   "metadata": {},
   "source": [
    "Changing the subtensor have effect on the initial tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdb352b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point[0] = 10\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4c78b",
   "metadata": {},
   "source": [
    "We can clone to prevent modifying the original tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74b9830a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point = points[1].clone()\n",
    "second_point[0] = 20.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107bdced",
   "metadata": {},
   "source": [
    "### 3.8.2 Transposing without copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53a8e0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aac597d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef55c04",
   "metadata": {},
   "source": [
    "Both have the same storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bc5943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56b6e5",
   "metadata": {},
   "source": [
    "Only differ on shape and stride:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "667c9562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (1, 2))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride(), points_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81061caf",
   "metadata": {},
   "source": [
    "### 3.8.3 Transposing in higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73dbc911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8a6a443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "20ff57cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "daa11975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc38ae8",
   "metadata": {},
   "source": [
    "### 3.8.4 Contiguous tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b43b63e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f065d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b6517",
   "metadata": {},
   "source": [
    "Converting a tensor to contiguous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dee71194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d5d23b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c9afbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4987ba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3fec571f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5b23037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3014d802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1b6430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 5.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d1e05",
   "metadata": {},
   "source": [
    "## 3.9 Moving tensors to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f034a16",
   "metadata": {},
   "source": [
    "### 3.9.1 Managing a tensor's device attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2f99c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c4184d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  2.],\n",
       "        [10.,  6.],\n",
       "        [ 4.,  2.]], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = 2 * points_gpu\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fe6eb",
   "metadata": {},
   "source": [
    "Move back to CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b62e3588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  2.],\n",
       "        [10.,  6.],\n",
       "        [ 4.,  2.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_cpu = points_gpu.to(device='cpu')\n",
    "points_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb212ea4",
   "metadata": {},
   "source": [
    "## 3.10 NumPy interoperability\n",
    "Convert to numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f0b8755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9472144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb032d6d",
   "metadata": {},
   "source": [
    "Convert back to torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1205a6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points2 = torch.from_numpy(points_np)\n",
    "points2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623c9d9",
   "metadata": {},
   "source": [
    "## 3.12 Serializing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "718112c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, '../data/ch3/points.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "47ed2694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points3 = torch.load('../data/ch3/points.t')\n",
    "points3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8dc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
