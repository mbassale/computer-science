{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9c077b",
   "metadata": {},
   "source": [
    "# Chapter 3: Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad36c8",
   "metadata": {},
   "source": [
    "### Python Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cb0d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1.0, 2.0, 1.0]\n",
    "a[2] = 3.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed62820",
   "metadata": {},
   "source": [
    "## 3.1 Constructing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a73593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b09274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395caa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b8620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11dd74d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ccde37",
   "metadata": {},
   "source": [
    "## 3.2 Anatomy of tensors\n",
    "\n",
    "Example: store 3 vertices of coords (4,1), (5,3) and (2,1) using a 1D tensor with even-indexes for x and odd-indexes for y coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9e3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a308da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points2 = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127f7af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points == points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947cd233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points - points2 == torch.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e26aaf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points + points2 == 2*points2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a619a",
   "metadata": {},
   "source": [
    "First coord:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d6d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99decda5",
   "metadata": {},
   "source": [
    "Storing the coords as a 2D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b4bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6c127",
   "metadata": {},
   "source": [
    "To know about the tensor dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0e7ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da9b97",
   "metadata": {},
   "source": [
    "Initialize the tensor by providing dimensions as a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29728d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3, 2)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd653e0",
   "metadata": {},
   "source": [
    "Accessing the elements using two indexes (like in matlab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e984be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7345809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be02e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[-1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23d4b88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4., 1.]), tensor([5., 3.]), tensor([2., 1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0], points[1], points[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b96a5",
   "metadata": {},
   "source": [
    "## 3.3 Indexing tensors\n",
    "Same indexing operators as python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cb59d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = list(range(6))\n",
    "some_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a4cc8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b56cc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e3b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d575d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d4585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aaede7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[1:4:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2c319",
   "metadata": {},
   "source": [
    "Same applies to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "879ed8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a990d7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c317e69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27c29cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a29d58fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "141808b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4., 1.],\n",
       "          [5., 3.],\n",
       "          [2., 1.]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None][None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b5150",
   "metadata": {},
   "source": [
    "## 3.4 Named tensors\n",
    "Just like structs, shapes, dicts, tensor labels to each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90774c97",
   "metadata": {},
   "source": [
    "We have an image and we want to convert to grayscale, in this example we use random values because we're lazy. The format if intensities of for each R, G and B channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b1cdf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2019,  0.0291,  0.2253,  1.1314, -0.0857],\n",
       "         [-0.2802,  0.3447, -1.0402,  0.1048,  0.1177],\n",
       "         [ 0.0358,  0.3354, -0.1171,  0.7412, -0.4129],\n",
       "         [-1.3866, -0.1343, -0.7752,  0.7502,  1.0500],\n",
       "         [-0.4012, -0.3991, -0.4020, -1.0559,  1.4396]],\n",
       "\n",
       "        [[-1.6730,  0.3079,  0.0596, -2.4580, -0.1420],\n",
       "         [ 1.7095, -0.7220,  0.4074, -1.2165, -0.0279],\n",
       "         [ 0.3373,  0.2810,  2.5113, -0.9640, -1.1281],\n",
       "         [ 0.1005,  2.0009,  1.0146,  1.0085, -0.6816],\n",
       "         [ 1.2192,  1.5790,  1.9703, -0.4926, -0.2932]],\n",
       "\n",
       "        [[ 0.0572,  2.5672, -1.2032, -1.3472,  0.2408],\n",
       "         [-1.2340, -0.1913, -2.0520, -0.0620,  1.0775],\n",
       "         [ 1.7802, -0.3630,  0.2757, -2.5171, -1.0917],\n",
       "         [ 0.3446, -0.3541,  0.7042, -0.8060,  0.1516],\n",
       "         [ 1.0678,  1.1950, -1.0627,  0.7912, -1.1572]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcbea5d",
   "metadata": {},
   "source": [
    "To convert to grayscale we use [Luma](https://en.wikipedia.org/wiki/Luma_(video)) to calculate the greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecb0dbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d456b707",
   "metadata": {},
   "source": [
    "Also, lets suppose we have 2 batches of images, so we have another tensor dimension, the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeb81613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.9193, -1.9245, -0.1953, -0.6917, -2.5867],\n",
       "          [ 0.2404, -1.3153,  0.3286, -0.8457,  1.1576],\n",
       "          [-1.4980,  2.0750, -0.1323,  0.1644, -0.8796],\n",
       "          [ 1.7223, -0.8358,  0.8544, -2.6090, -0.3685],\n",
       "          [ 1.5813, -0.7120,  0.7098, -1.2153,  0.4559]],\n",
       "\n",
       "         [[ 0.5737, -0.5037, -0.3221,  0.2539, -0.0382],\n",
       "          [-0.6024, -0.8374,  0.1164, -0.9723, -0.4414],\n",
       "          [ 0.8251,  0.2290, -0.4270, -1.0503, -1.3358],\n",
       "          [ 0.7316,  1.0266,  1.1822,  1.2336,  0.3796],\n",
       "          [ 1.6702,  1.3791, -0.7570, -0.8553,  1.0756]],\n",
       "\n",
       "         [[-0.1027, -0.1253,  0.7635,  0.5333, -1.2850],\n",
       "          [-1.7556,  1.9921,  1.6188, -0.4864,  0.1538],\n",
       "          [ 0.9642,  0.4187, -0.3216,  0.3302, -0.5851],\n",
       "          [-0.3434,  0.1343, -0.1494, -0.4778, -0.7679],\n",
       "          [ 0.1990,  0.1621, -1.0591,  1.7681,  0.2150]]],\n",
       "\n",
       "\n",
       "        [[[-0.3129, -1.1529,  1.1229, -1.1357,  1.6548],\n",
       "          [-0.0112, -2.1223, -0.9160, -1.0034,  0.5047],\n",
       "          [ 1.4693,  0.8957,  0.3274,  1.9304, -0.9800],\n",
       "          [ 0.8279, -1.3205, -1.0182,  0.3289, -2.0174],\n",
       "          [ 1.8896, -0.2046,  2.8584, -1.1736, -0.3202]],\n",
       "\n",
       "         [[ 1.0211,  1.8738, -1.0707, -0.9043,  0.1101],\n",
       "          [ 1.1299,  0.1047,  0.5080,  1.4269, -2.0631],\n",
       "          [ 0.6838,  1.3953, -0.1515, -0.5151, -1.3479],\n",
       "          [-0.6191,  0.4205, -0.2389,  0.7453,  0.7438],\n",
       "          [-1.8571,  0.0740,  0.2673,  0.7341,  0.9174]],\n",
       "\n",
       "         [[-0.1001,  0.6444,  0.8027,  0.8263,  0.0511],\n",
       "          [ 1.2954, -0.6490, -0.7493, -1.0516, -0.3693],\n",
       "          [-1.2182, -1.5573, -0.8506, -0.8675,  3.1987],\n",
       "          [ 0.4402,  0.0263, -0.9619,  0.3205, -1.3470],\n",
       "          [ 0.5662,  0.0647,  0.7198, -0.4443,  1.3504]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aca21c",
   "metadata": {},
   "source": [
    "We calculate the means from the last 3 dimensions, because RBG channels are at the end, so we generate a new tensor with the `mean(dim -3, dim -2, dim -1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90e72dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9393,  0.9680, -0.3061, -0.8913,  0.0044],\n",
       "         [ 0.0651, -0.1895, -0.8949, -0.3912,  0.3891],\n",
       "         [ 0.7178,  0.0845,  0.8900, -0.9133, -0.8776],\n",
       "         [-0.3138,  0.5041,  0.3145,  0.3175,  0.1733],\n",
       "         [ 0.6286,  0.7917,  0.1685, -0.2524, -0.0036]]),\n",
       " tensor([[[ 0.7968, -0.8512,  0.0820,  0.0318, -1.3033],\n",
       "          [-0.7059, -0.0535,  0.6879, -0.7681,  0.2900],\n",
       "          [ 0.0971,  0.9076, -0.2937, -0.1852, -0.9335],\n",
       "          [ 0.7035,  0.1084,  0.6291, -0.6177, -0.2522],\n",
       "          [ 1.1502,  0.2764, -0.3688, -0.1009,  0.5822]],\n",
       " \n",
       "         [[ 0.2027,  0.4551,  0.2850, -0.4046,  0.6053],\n",
       "          [ 0.8047, -0.8888, -0.3858, -0.2093, -0.6425],\n",
       "          [ 0.3116,  0.2446, -0.2249,  0.1826,  0.2903],\n",
       "          [ 0.2164, -0.2912, -0.7397,  0.4649, -0.8735],\n",
       "          [ 0.1996, -0.0219,  1.2818, -0.2946,  0.6492]]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive, batch_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4db857c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c54dbe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac53c9b",
   "metadata": {},
   "source": [
    "### Using named tensors for self-documenting code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b1304",
   "metadata": {},
   "source": [
    "Specifying dimension names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ee84a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bassa\\AppData\\Local\\Temp\\ipykernel_9956\\2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10/core/TensorImpl.h:1761.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8edb6",
   "metadata": {},
   "source": [
    "Creating new tensors with dimension names from unamed tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92f235f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch_named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print('img named:', img_named.shape, img_named.names)\n",
    "print('batch_named:', batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b8bad",
   "metadata": {},
   "source": [
    "Create a new tensor aligned with the same column/dim ordering by using names to match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60f9e832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d3586",
   "metadata": {},
   "source": [
    "Tensor operations can take a named dimesion as arg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d008fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50c9bc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], names=('rows', 'columns'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named - (img_named*weights_aligned).sum('channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a47cd7",
   "metadata": {},
   "source": [
    "Names checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f008520f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9956\\9594579.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgray_named\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_named\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights_named\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'channels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match."
     ]
    }
   ],
   "source": [
    "gray_named = (img_named[..., :3] * weights_named).sum('channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b526a7a",
   "metadata": {},
   "source": [
    "Drop named tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d3b6c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dce36e",
   "metadata": {},
   "source": [
    "## 3.5 Tensor element types\n",
    "\n",
    "Tensor constructor argument `dtype` specifies the numerical data type of each tensor scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f1976",
   "metadata": {},
   "source": [
    "### 3.5.3 Managing a tensor's dtype attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bf59c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e47d1f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]], dtype=torch.float64),\n",
       " torch.float64,\n",
       " torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points, double_points.dtype, torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d2682a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]], dtype=torch.int16),\n",
       " torch.int16,\n",
       " torch.int16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_points, short_points.dtype, torch.int16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f9a3c",
   "metadata": {},
   "source": [
    "Using casting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da834a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()\n",
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e724fb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(10, 2).to(dtype=torch.short)\n",
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d516efe",
   "metadata": {},
   "source": [
    "Types are converted to the larget type automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "879a0cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.to(torch.short)\n",
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48da891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
