{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "metadata": {
   "interpreter": {
    "hash": "17323f77f47784bff925f286cefcaaa1e5bd347c6c6ae43058b18498b4cc0809"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Study of Dice Rolls Probabilities with and without Concurrency.\n",
    "\n",
    "In this notebook we will calculate the probability of outcome when rolling two dices at the same moment. We can\n",
    "calculate exactly what are the probabilities of obtaining a particular result.\n",
    "For example, if we have two dices with 6 sides, with faces numbered from 1 to 6, and we roll both dices at the same\n",
    "moment, we can obtain the following possible outcomes:\n",
    "2, 3, 4, 5, 6, ... , 12  \n",
    "So if we enumerate exhaustively all possible combinations, we can calculate the probability distribution for each\n",
    "outcome, the following function `dice_probabilities` calculates the probability distribution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%precision 3\n",
    "SIDES = 6\n",
    "\n",
    "def dice_probabilities() -> list:\n",
    "    \"\"\"\n",
    "    Returns an array of probabilities to obtain a certain result when rolling two dices.\n",
    "    \"\"\"\n",
    "    dist = [0 for _ in range(2 * SIDES + 1)]\n",
    "    for i in range(1, SIDES + 1):\n",
    "        for j in range(1, SIDES + 1):\n",
    "            dist[i + j] += 1\n",
    "    for k in range(len(dist)):\n",
    "        dist[k] /= SIDES * SIDES\n",
    "    return dist"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "As we can see, there is no probability of obtaining 0 or 1 as result, because the minimum result is 2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "expected_probabilities = dice_probabilities()\n",
    "print(expected_probabilities)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.027777777777777776, 0.05555555555555555, 0.08333333333333333, 0.1111111111111111, 0.1388888888888889, 0.16666666666666666, 0.1388888888888889, 0.1111111111111111, 0.08333333333333333, 0.05555555555555555, 0.027777777777777776]\n"
     ]
    }
   ]
  },
  {
   "source": [
    "Also, we can check that the probability distribution adds up to 1, so our calculation is in principle correct."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.000"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(expected_probabilities)"
   ]
  },
  {
   "source": [
    "## Rolling Dices\n",
    "Now we can check if this probability distribution is correct by simulating the process of rolling the dices with a\n",
    "computer. First we will do it using a serial approach, without multiprocessing, after that, we will use a concurrent\n",
    "approach with Python multiprocessing module, then we will compare both to see how concurrency improves this kind of\n",
    "cpu-bound calculations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We need to import some modules to help us with random number generation, rounding, and timing the algorithm runtime."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "source": [
    "The function `roll_dices` will roll a specified number of times and accumulate the results in the `dice_counts` list,\n",
    "then we will divide the counts by the total number of rolls to obtain the actual probability distribution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def roll_dices(number_rolls):\n",
    "    dice_counts = [0 for _ in range(2 * SIDES + 1)]\n",
    "    for i in range(number_rolls):\n",
    "        dice1 = random.randint(1, SIDES)\n",
    "        dice2 = random.randint(1, SIDES)\n",
    "        dice_counts[dice1 + dice2] += 1\n",
    "    return [dice_count / number_rolls for dice_count in dice_counts]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "source": [
    "Now we run our experiment with 10 million rolls, also we time the execution to compare with concurrency later."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roll count: 10000000\n",
      "--- 13560.353 ms ---\n",
      "[0.0, 0.0, 0.0276678, 0.055521, 0.0834503, 0.110929, 0.1390298, 0.166541, 0.1390419, 0.1110754, 0.0833736, 0.0555205, 0.0278497]\n"
     ]
    }
   ],
   "source": [
    "roll_count = 10000000\n",
    "print(f'Roll count: {roll_count}')\n",
    "start_time = time.time()\n",
    "actual_probabilities = roll_dices(roll_count)\n",
    "end_time = time.time()\n",
    "serial_running_time = (end_time - start_time) * 1000\n",
    "print(f'--- {serial_running_time:.3f} ms ---') \n",
    "print(actual_probabilities)"
   ]
  },
  {
   "source": [
    "As you can see the execution of this algorithm took approx. 14 seconds to complete, without concurrency (using only\n",
    "1-core of the machine).\n",
    "Now lets check if the probabilities look good."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.000"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(actual_probabilities)"
   ]
  },
  {
   "source": [
    "The probabilities sum is ok, so now let's calculate the cumulative difference between the expected probabilities and\n",
    "the actual probabilities."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Diff: 0.001\n"
     ]
    }
   ],
   "source": [
    "cumulative_diff = sum([abs(actual_probabilities[i] - expected_probabilities[i]) for i in range(len(actual_probabilities))])\n",
    "print(f'Cumulative Diff: {cumulative_diff:.3f}')"
   ]
  },
  {
   "source": [
    "The difference is very small, so we can see that our initial calculation was correct, now we can move onto the\n",
    "concurrent implementation, to see if we can make this algorithm faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Concurrent Dice Rolling with Python Multiprocessing\n",
    "\n",
    "Why we use multiprocessing and not multithreading? The Python interpreter has a Global Interpreter Lock (GIL)\n",
    "that prohibits multiple threads to execute python instructions. So if you use multithreading for cpu-bound processing\n",
    "like in this case, you will have thread contention, and the execution will be serial, not parallel, so you will lose the\n",
    "benefits of concurrency. For IO-bound processing, for example, reading multiple files or socket communications,\n",
    "threading is a good alternative, because each thread will wait for IO events at the same moment.\n",
    "\n",
    "To allow multiprocessing to execute parallel tasks inside a Jupyter Notebook, it's better to have the processing task,\n",
    "in this case `roll_dices_task`, in a separate external module (`dice_multiprocessing`), so the multiprocessing module\n",
    "will find the function to execute. If you define the function inside the Jupyter Notebook, the multiprocessing module\n",
    "won't be able to find the function to execute, and it will raise an exception."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We will need:\n",
    "- `roll_dices_task`: this function will simulate the dice rolling process.\n",
    "- `Process`: class to execute tasks.\n",
    "- `Array`: this class will allow us to create arrays that can be shared with the parallel processes, these arrays will\n",
    "store the probability distributions, one per process.\n",
    "- `cpu_count`: this function returns the number of hardware cpus or cores that are available for multiprocessing. It's\n",
    "advised to execute just one process per core, to prevent serialization of tasks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dice_multiprocessing import roll_dices_task\n",
    "from multiprocessing import Process, Array, cpu_count"
   ]
  },
  {
   "source": [
    "Let's see the definition of the `roll_dices_task`, we will see that is almost the same as the previous `roll_dices`\n",
    "function. The difference is that we use an `Array` argument instead of a list, also we return the dice counts instead\n",
    "of the probabilities, because we will add these counts in the main process logic and then calculate the probability\n",
    "distribution.\n",
    "\n",
    "```\n",
    "def roll_dices_task(rolls_per_process: int, dice_counts: Array):\n",
    "    for i in range(rolls_per_process):\n",
    "        dice1 = random.randint(1, SIDES)\n",
    "        dice2 = random.randint(1, SIDES)\n",
    "        dice_counts[dice1 + dice2] += 1\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We calculate the number of rolls that will be executed per process."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roll count: 10000000\n",
      "Roll per process: 625000\n"
     ]
    }
   ],
   "source": [
    "number_processes = cpu_count()\n",
    "roll_count = 10000000\n",
    "print(f'Roll count: {roll_count}')\n",
    "rolls_per_process = math.ceil(roll_count / number_processes)\n",
    "print(f'Roll per process: {rolls_per_process}')"
   ]
  },
  {
   "source": [
    "Then we create an array of `Array` objects that will be used to store the probability distribution of each of the\n",
    "running tasks. The arguments are as follows:\n",
    "- 1st argument: the datatype, in this case an unsigned int (we are counting the number of rolls)\n",
    "Please check the [arrays](https://docs.python.org/3/library/array.html#module-array) module for reference on data types.\n",
    "- 2nd argument: is the initial values used to fill the array, a scalar or a sequence.\n",
    "- 3rd argument: `lock=False` means that the array will be used for communication between the parent process\n",
    "(this notebook process) and the tasks, and we don't expect to have concurrent access to the same array from multiple\n",
    "concurrent processes. It's better to enable lock only when it's necessary, because acquiring the lock consumes\n",
    "considerable time, and this will slow down the concurrent execution making the multiprocessing strategy slower than\n",
    "using a serial approach."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [Array('I', [0 for _ in range(2 * SIDES + 1)], lock=False) for _ in range(number_processes)]"
   ]
  },
  {
   "source": [
    "We need to create each process object specifying the task to execute and the arguments. In this case:\n",
    "- `roll_dices_task`: this function defined in an external module will simulate the rolling dices using python `random`\n",
    "module.\n",
    "- `rolls_per_process`: specifies how many times the dices will roll.\n",
    "- `results[i]`: this is the corresponding `Array` object that will be used to store the probability distributions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = [Process(target=roll_dices_task, args=(rolls_per_process, results[i])) for i in range(number_processes)]"
   ]
  },
  {
   "source": [
    "After creating the process objects we need to call `start` to begin the execution of each task. Also, we need to pause\n",
    "the notebook process and resume only after each task is finish, for these, we use the `join` method, this will wait\n",
    "until the process is finished and then continue execution.\n",
    "Finally, we calculate the running time to compare with the serial approach."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2318.639 ms ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for process in processes:\n",
    "    process.start()\n",
    "for process in processes:\n",
    "    process.join()\n",
    "end_time = time.time()\n",
    "multiprocessing_running_time = (end_time - start_time) * 1000\n",
    "print(f'--- {multiprocessing_running_time:.3f} ms ---')"
   ]
  },
  {
   "source": [
    "We can see that multiprocessing is way faster than the serial approach, when it's used without synchronization\n",
    "mechanisms like mutexes. In this specific example, is more than 6 times faster than the serial approach, on my 16 core\n",
    "machine.\n",
    "If we extrapolate to a calculation of several hours, multiprocessing or multithreading can save a lot of time\n",
    "and processing resources (cost savings if you're renting a cloud service)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5.848"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serial_running_time / multiprocessing_running_time"
   ]
  },
  {
   "source": [
    "Finally, let's check if the results are correct by comparing to the probability distribution with the previously\n",
    "calculated distribution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 278332, 554878, 834009, 1112562, 1387877, 1665783, 1390180, 1110856, 832094, 555367, 278062]\n"
     ]
    }
   ],
   "source": [
    "dice_counts = [0 for _ in range(2 * SIDES + 1)]\n",
    "for i in range(len(dice_counts)):\n",
    "    dice_counts[i] = 0\n",
    "    for result in results:\n",
    "        dice_counts[i] += result[i]\n",
    "print(dice_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0278332, 0.0554878, 0.0834009, 0.1112562, 0.1387877, 0.1665783, 0.139018, 0.1110856, 0.0832094, 0.0555367, 0.0278062]\n"
     ]
    }
   ],
   "source": [
    "actual_probabilities = [0 for _ in range(2 * SIDES + 1)]\n",
    "for i in range(len(dice_counts)):\n",
    "    actual_probabilities[i] = dice_counts[i] / roll_count\n",
    "print(actual_probabilities)"
   ]
  },
  {
   "source": [
    "We can see that the cumulative difference is very low, so the multiprocessing approach didn't affect the general result,\n",
    "only made the calculation faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Diff: 0.0008512222222221769\n"
     ]
    }
   ],
   "source": [
    "diff = sum([abs(actual_probabilities[i] - expected_probabilities[i]) for i in range(len(actual_probabilities))])\n",
    "print(f'Cumulative Diff: {diff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusions\n",
    "- This experiment serves as an example of how multiprocessing can decrease the running time of an algorithm by\n",
    "exploiting concurrency, but we must be careful that it doesn't replace a good algorithm design. It's known that a better\n",
    "algorithm design will win over increasing the number of cores or execution speed of a machine.\n",
    "- We need to be careful with multiprocessing and synchronization mechanisms like mutexes (Locks on Python docs), because\n",
    "a mutex or lock can decrease the speed considerably, slowing the execution of the multiprocessing strategy to a point\n",
    "that is possible to run slower than a serial strategy.\n",
    "- When the dataset to process is small, there is no point in using multiprocessing, in this case we had 10 million\n",
    "rolls, but if we had less, it's better to use a serial strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}